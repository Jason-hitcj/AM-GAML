import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, SAGEConv, GATConv, HeteroConv, Linear
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    average_precision_score
)
import numpy as np

# -------------------------------
# æ¨¡å‹å®šä¹‰ï¼šå¼‚æ„å›¾ GCN / SAGE / GAT (ä¸æ‚¨çš„ä¸€è‡´ï¼Œæ— éœ€ä¿®æ”¹)
# -------------------------------
class HeteroGNN(torch.nn.Module):
    def __init__(self, metadata, in_channels_dict, hidden_channels, out_channels, model_type='sage'):
        super().__init__()
        if model_type == 'sage':
            conv_class = SAGEConv
        elif model_type == 'gcn':
            conv_class = GCNConv
        elif model_type == 'gat':
            # GATConvçš„è¾“å…¥æ ¼å¼ä¸å…¶ä»–ä¸åŒï¼Œéœ€è¦ç‰¹åˆ«å¤„ç†
            conv_class = lambda in_channels, out_channels: GATConv(in_channels, out_channels, heads=1, add_self_loops=False)
        else:
            raise ValueError("model_type must be 'sage', 'gcn', or 'gat'")

        self.conv1 = HeteroConv({
            edge_type: conv_class(
                # GATConvéœ€è¦ä¸€ä¸ªæ•´æ•°ï¼Œè€Œä¸æ˜¯å…ƒç»„
                (in_channels_dict[edge_type[0]] if model_type != 'gat' else in_channels_dict[edge_type[0]], 
                 in_channels_dict[edge_type[2]]),
                hidden_channels
            )
            for edge_type in metadata[1]
        }, aggr='sum')

        self.conv2 = HeteroConv({
            edge_type: conv_class(hidden_channels, hidden_channels)
            for edge_type in metadata[1]
        }, aggr='sum')

        self.lin = Linear(hidden_channels, out_channels)

    def forward(self, x_dict, edge_index_dict):
        x_dict = self.conv1(x_dict, edge_index_dict)
        x_dict = {key: F.relu(x) for key, x in x_dict.items()}
        x_dict = self.conv2(x_dict, edge_index_dict)
        return self.lin(x_dict['customer'])


# -------------------------------
# è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ (æ–°å¢)
# -------------------------------
def calculate_metrics(y_true, y_pred, y_prob):
    """è®¡ç®—å¹¶è¿”å›ä¸€å¥—å®Œæ•´çš„åˆ†ç±»è¯„ä¼°æŒ‡æ ‡"""
    metrics = {}
    metrics['Accuracy']  = accuracy_score(y_true, y_pred)
    # å‡è®¾æ˜¯äºŒåˆ†ç±»ï¼Œå¹¶ä¸”æ­£ç±»æ ‡ç­¾ä¸º1
    metrics['Precision'] = precision_score(y_true, y_pred, zero_division=0)
    metrics['Recall']    = recall_score(y_true, y_pred, zero_division=0)
    metrics['F1 Score']  = f1_score(y_true, y_pred, zero_division=0)
    metrics['AUPRC']     = average_precision_score(y_true, y_prob)
    return metrics


# -------------------------------
# è®­ç»ƒ + éªŒè¯ + æµ‹è¯• ä¸»å‡½æ•° (å·²ä¿®æ”¹)
# -------------------------------
def train_and_evaluate(data, model_type='sage', hidden_channels=64, epochs=30, lr=0.005, verbose_interval=10):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    data = data.to(device)

    in_channels_dict = {node_type: data[node_type].x.size(1) for node_type in data.node_types}
    out_channels = int(data['customer'].y.max().item()) + 1

    model = HeteroGNN(
        metadata=data.metadata(),
        in_channels_dict=in_channels_dict,
        hidden_channels=hidden_channels,
        out_channels=out_channels,
        model_type=model_type
    ).to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    print(f"\nğŸ”§ Start training with model: {model_type.upper()}")

    for epoch in range(1, epochs + 1):
        model.train()
        optimizer.zero_grad()
        out = model(data.x_dict, data.edge_index_dict)

        loss = F.cross_entropy(out[data['customer'].train_mask], data['customer'].y[data['customer'].train_mask])
        loss.backward()
        optimizer.step()

        # --- åœ¨éªŒè¯é›†ä¸Šè¯„ä¼° ---
        if epoch % verbose_interval == 0 or epoch == 1:
            model.eval()
            with torch.no_grad():
                out = model(data.x_dict, data.edge_index_dict)
                # ä½¿ç”¨softmaxè·å–æ¦‚ç‡
                probs = F.softmax(out, dim=1)
                pred = probs.argmax(dim=1)

                # æå–éªŒè¯é›†æ•°æ®
                val_mask = data['customer'].val_mask
                val_true = data['customer'].y[val_mask].cpu().numpy()
                val_pred = pred[val_mask].cpu().numpy()
                val_prob = probs[val_mask][:, 1].cpu().numpy() # å–æ­£ç±»çš„æ¦‚ç‡

                # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
                val_metrics = calculate_metrics(val_true, val_pred, val_prob)
                
                print(f"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {val_metrics['Accuracy']:.4f} | Val F1: {val_metrics['F1 Score']:.4f} | Val AUPRC: {val_metrics['AUPRC']:.4f}")

    # --- æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° ---
    print("\n===== GNNæœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡ =====")
    model.eval()
    with torch.no_grad():
        out = model(data.x_dict, data.edge_index_dict)
        probs = F.softmax(out, dim=1)
        pred = probs.argmax(dim=1)

        test_mask = data['customer'].test_mask
        test_true = data['customer'].y[test_mask].cpu().numpy()
        test_pred = pred[test_mask].cpu().numpy()
        test_prob = probs[test_mask][:, 1].cpu().numpy()

        test_metrics = calculate_metrics(test_true, test_pred, test_prob)
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    for name, value in test_metrics.items():
        print(f"{name:<12}: {value:.4f}")
        
    return model, test_metrics


# -------------------------------
# ä¸»ç¨‹åºæ‰§è¡Œéƒ¨åˆ†
# -------------------------------
if __name__ == '__main__':
    # åŠ è½½å›¾æ•°æ®
    try:
        data = torch.load('data_new/hetero_graph.pt')
    except FileNotFoundError:
        print("é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ° 'data_new/hetero_graph.pt'ã€‚è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚")
        exit()

    # --- è®­ç»ƒå¹¶è¯„ä¼° GraphSAGE ---
    sage_model, sage_metrics = train_and_evaluate(
        data, model_type='sage', epochs=100, lr=0.005
    )

    # # --- è®­ç»ƒå¹¶è¯„ä¼° GAT ---
    # gat_model, gat_metrics = train_and_evaluate(
    #     data, model_type='gat', epochs=200, lr=0.005, verbose_interval=20
    # )